{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HandWriting_numbers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning: Reconocimiento de números escritos a mano\n",
        "\n",
        "> En este tutorial, tomaremos imagenes de números escritos a mano, del 0 al 9, y enseñaremos a nuestra inteligencia a saber qué número sale en la foto.\n",
        "\n"
      ],
      "metadata": {
        "id": "jLZliV31f9Gh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos TensorFlow:"
      ],
      "metadata": {
        "id": "GWPXHHtFxxhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.__version__"
      ],
      "metadata": {
        "id": "IuJrHktOhHMB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e29a123e-493f-4ff9-87a9-a3d10957ea32"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos el dataset de las imagenes con números escritos a mano. Normalizamos las imagenes para tener valores entre 0 y 1, para hacer más fácil el aprendizaje de la ia."
      ],
      "metadata": {
        "id": "d0Y5ZfoKioPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
        "x_test = tf.keras.utils.normalize(x_test, axis=1)"
      ],
      "metadata": {
        "id": "V4_XZkX_hNXo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos un modelo (secuencial), y le añadimos las capas. \n",
        "La última capa (Output) suele tener un valor igual al número de elementos del Dataset. Es decir, si nuestro Dataset tiene 10 imagenes, tendrá un valor de 10, si tiene 20, 20."
      ],
      "metadata": {
        "id": "KfvAnQQFxhPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "# Output Layer\n",
        "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21P-Z5iIotiD",
        "outputId": "b72d9bb8-aa76-4b57-d39c-f3921d467110"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2581 - accuracy: 0.9251\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1048 - accuracy: 0.9674\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0717 - accuracy: 0.9773\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f308b1e3310>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilamos el modelo, optimizándolo para mejores resultados. \n",
        "Entrenamos el modelo."
      ],
      "metadata": {
        "id": "hPEwmtFky5Tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=3)"
      ],
      "metadata": {
        "id": "-l3L2vLny4VR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluamos los resultados del modelo."
      ],
      "metadata": {
        "id": "C_DMTcpwzWO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
        "print(val_loss, val_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtkQFZYVoVIE",
        "outputId": "8ea46c8e-994e-4f73-a30a-5bf8ac26e622"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0858 - accuracy: 0.9723\n",
            "0.08582133799791336 0.9722999930381775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizaremos Matplotlib.pyplot para mostrar la imagen con el número que le pasemos al modelo:"
      ],
      "metadata": {
        "id": "4XWxzsIkjr5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(x_train[5], cmap= plt.cm.binary)\n",
        "plt.show()\n",
        "#print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "z8a-ZSaSjwgi",
        "outputId": "b170d0f3-1016-4c49-9929-aa0b4b770820"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardamos el modelo:"
      ],
      "metadata": {
        "id": "Iqy5hLZYzlox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('handwriting_num_predict.model')"
      ],
      "metadata": {
        "id": "8istHgfpp4ux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad53c592-7e81-47c3-eaa1-d94f354d8699"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: handwriting_num_predict.model/assets\n"
          ]
        }
      ]
    }
  ]
}